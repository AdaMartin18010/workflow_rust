# åŸºäºTemporalæ¡†æ¶çš„Rust 1.90å·¥ä½œæµç³»ç»Ÿå®Œæ•´è®¾è®¡

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

**è®¾è®¡ç†å¿µ**: å®Œå…¨éµå¾ªTemporalæ¡†æ¶çš„è®¾è®¡å“²å­¦ï¼Œä½¿ç”¨Rust 1.90å®ç°
**ç›®æ ‡**: åˆ›å»ºTemporal-nativeçš„Rustå·¥ä½œæµåº“
**ç‰ˆæœ¬**: 1.0.0-temporal-native

---

## 1. Temporalæ ¸å¿ƒæ¦‚å¿µåœ¨Rustä¸­çš„æ˜ å°„

### 1.1 æ¶æ„å¯¹åº”å…³ç³»

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Temporalæ¦‚å¿µ â†’ Rust 1.90å®ç°æ˜ å°„                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Temporal Workflow    â†’  #[workflow] async fn                   â”‚
â”‚  Temporal Activity    â†’  #[activity] async fn                   â”‚
â”‚  Temporal Worker      â†’  WorkflowWorker struct                  â”‚
â”‚  Task Queue           â†’  TaskQueue<T> (async channel)           â”‚
â”‚  Signal               â†’  Signal<T> (typed channel)              â”‚
â”‚  Query                â†’  Query<T> trait                         â”‚
â”‚  Child Workflow       â†’  ChildWorkflowHandle<T>                 â”‚
â”‚  Timer                â†’  WorkflowTimer (persistent)             â”‚
â”‚  Event History        â†’  EventLog (event sourcing)              â”‚
â”‚  Saga                 â†’  Saga<T> with compensation              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ ¸å¿ƒç±»å‹ç³»ç»Ÿ

```rust
// å®Œå…¨åŸºäºTemporalçš„ç±»å‹è®¾è®¡

/// å·¥ä½œæµä¸Šä¸‹æ–‡ - Temporal WorkflowContextçš„Rustå®ç°
pub struct WorkflowContext {
    /// å·¥ä½œæµID
    workflow_id: WorkflowId,
    /// è¿è¡ŒID
    run_id: RunId,
    /// å·¥ä½œæµç±»å‹
    workflow_type: String,
    /// ä»»åŠ¡é˜Ÿåˆ—
    task_queue: String,
    /// æ‰§è¡Œè¶…æ—¶
    execution_timeout: Option<Duration>,
    /// äº‹ä»¶å†å²
    history: Arc<RwLock<EventHistory>>,
    /// Signalé€šé“
    signals: Arc<SignalRegistry>,
    /// Queryå¤„ç†å™¨
    queries: Arc<QueryRegistry>,
}

/// å·¥ä½œæµIDç±»å‹
#[derive(Debug, Clone, Hash, Eq, PartialEq, Serialize, Deserialize)]
pub struct WorkflowId(String);

/// è¿è¡ŒIDç±»å‹
#[derive(Debug, Clone, Hash, Eq, PartialEq, Serialize, Deserialize)]
pub struct RunId(Uuid);

/// Activityä¸Šä¸‹æ–‡ - Temporal ActivityContextçš„Rustå®ç°
pub struct ActivityContext {
    /// Activity ID
    activity_id: ActivityId,
    /// å·¥ä½œæµæ‰§è¡Œä¿¡æ¯
    workflow_execution: WorkflowExecution,
    /// Activityç±»å‹
    activity_type: String,
    /// å¿ƒè·³
    heartbeat: Arc<HeartbeatHandle>,
    /// å–æ¶ˆä»¤ç‰Œ
    cancellation: CancellationToken,
}

/// å·¥ä½œæµæ‰§è¡Œä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowExecution {
    pub workflow_id: WorkflowId,
    pub run_id: RunId,
}

/// Activity ID
#[derive(Debug, Clone, Hash, Eq, PartialEq, Serialize, Deserialize)]
pub struct ActivityId(String);
```

---

## 2. åŸºäºTemporalçš„å·¥ä½œæµå®šä¹‰

### 2.1 å·¥ä½œæµå®å®šä¹‰

```rust
// å·¥ä½œæµå®šä¹‰å® - å®Œå…¨æ¨¡ä»¿Temporalçš„@workflowè£…é¥°å™¨

/// å·¥ä½œæµå®šä¹‰å®
/// 
/// ç”¨æ³•:
/// ```rust
/// #[workflow]
/// async fn order_workflow(ctx: WorkflowContext, input: OrderInput) -> Result<OrderOutput> {
///     // å·¥ä½œæµé€»è¾‘
/// }
/// ```
#[proc_macro_attribute]
pub fn workflow(attr: TokenStream, item: TokenStream) -> TokenStream {
    // 1. è§£æå‡½æ•°å®šä¹‰
    // 2. éªŒè¯ç­¾å (å¿…é¡»æ˜¯async fnï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯WorkflowContext)
    // 3. ç”Ÿæˆå·¥ä½œæµæ³¨å†Œä»£ç 
    // 4. æ·»åŠ ç¡®å®šæ€§æ£€æŸ¥
    // 5. ç”Ÿæˆäº‹ä»¶è®°å½•ä»£ç 
}

/// Activityå®šä¹‰å®
/// 
/// ç”¨æ³•:
/// ```rust
/// #[activity]
/// async fn process_payment(ctx: ActivityContext, input: PaymentInput) -> Result<PaymentResult> {
///     // Activityé€»è¾‘
/// }
/// ```
#[proc_macro_attribute]
pub fn activity(attr: TokenStream, item: TokenStream) -> TokenStream {
    // 1. è§£æå‡½æ•°å®šä¹‰
    // 2. æ·»åŠ é‡è¯•é€»è¾‘åŒ…è£…
    // 3. æ·»åŠ è¶…æ—¶æ§åˆ¶
    // 4. æ·»åŠ å¿ƒè·³æ”¯æŒ
    // 5. ç”ŸæˆActivityæ³¨å†Œä»£ç 
}
```

### 2.2 å®Œæ•´çš„å·¥ä½œæµç¤ºä¾‹

```rust
use temporal_rust::prelude::*;

/// è®¢å•å¤„ç†å·¥ä½œæµ - å®Œå…¨Temporalé£æ ¼
#[workflow]
pub async fn order_processing_workflow(
    ctx: WorkflowContext,
    input: OrderInput,
) -> Result<OrderOutput, WorkflowError> {
    // 1. æ‰§è¡ŒActivity - éªŒè¯è®¢å•
    let validation_result = ctx
        .execute_activity::<ValidateOrderActivity>(
            ActivityInput::new(input.clone()),
            ActivityOptions {
                start_to_close_timeout: Duration::from_secs(30),
                retry_policy: Some(RetryPolicy {
                    initial_interval: Duration::from_secs(1),
                    backoff_coefficient: 2.0,
                    maximum_interval: Duration::from_secs(60),
                    maximum_attempts: 3,
                    non_retryable_error_types: vec!["ValidationError".to_string()],
                }),
                ..Default::default()
            },
        )
        .await?;

    if !validation_result.is_valid {
        return Err(WorkflowError::ValidationFailed(validation_result.reason));
    }

    // 2. å¹¶è¡Œæ‰§è¡Œå¤šä¸ªActivities
    let (inventory_result, payment_result) = tokio::try_join!(
        ctx.execute_activity::<ReserveInventoryActivity>(
            ActivityInput::new(input.clone()),
            ActivityOptions::default(),
        ),
        ctx.execute_activity::<ProcessPaymentActivity>(
            ActivityInput::new(input.clone()),
            ActivityOptions::default(),
        ),
    )?;

    // 3. ä½¿ç”¨Signalç­‰å¾…å¤–éƒ¨ç¡®è®¤
    ctx.await_signal::<ApprovalSignal>("order_approval").await?;

    // 4. å‘è´§
    let shipment_result = ctx
        .execute_activity::<ShipOrderActivity>(
            ActivityInput::new(input.clone()),
            ActivityOptions::default(),
        )
        .await?;

    // 5. è¿”å›ç»“æœ
    Ok(OrderOutput {
        order_id: input.order_id,
        status: OrderStatus::Completed,
        shipment_tracking: shipment_result.tracking_number,
    })
}

/// éªŒè¯è®¢å•Activity
#[activity]
pub async fn validate_order_activity(
    ctx: ActivityContext,
    input: OrderInput,
) -> Result<ValidationResult, ActivityError> {
    // å‘é€å¿ƒè·³
    ctx.heartbeat().await?;

    // æ‰§è¡ŒéªŒè¯é€»è¾‘
    let is_valid = validate_order_logic(&input).await?;

    // æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
    if ctx.is_cancelled() {
        return Err(ActivityError::Cancelled);
    }

    Ok(ValidationResult {
        is_valid,
        reason: if is_valid { None } else { Some("Invalid order".to_string()) },
    })
}

/// é¢„è®¢åº“å­˜Activity
#[activity]
pub async fn reserve_inventory_activity(
    ctx: ActivityContext,
    input: OrderInput,
) -> Result<InventoryResult, ActivityError> {
    // å®é™…åº“å­˜é¢„è®¢é€»è¾‘
    inventory_service::reserve(&input.items).await
        .map_err(|e| ActivityError::ExecutionError(e.to_string()))
}

/// å¤„ç†æ”¯ä»˜Activity
#[activity]
pub async fn process_payment_activity(
    ctx: ActivityContext,
    input: OrderInput,
) -> Result<PaymentResult, ActivityError> {
    // å®é™…æ”¯ä»˜å¤„ç†é€»è¾‘
    payment_service::process(input.payment_info).await
        .map_err(|e| ActivityError::ExecutionError(e.to_string()))
}

/// å‘è´§Activity
#[activity]
pub async fn ship_order_activity(
    ctx: ActivityContext,
    input: OrderInput,
) -> Result<ShipmentResult, ActivityError> {
    // å®é™…å‘è´§é€»è¾‘
    shipping_service::ship(&input).await
        .map_err(|e| ActivityError::ExecutionError(e.to_string()))
}
```

---

## 3. Signalå’ŒQueryå®ç°

### 3.1 Signalç³»ç»Ÿè®¾è®¡

```rust
/// Signalå®šä¹‰trait
pub trait Signal: Serialize + DeserializeOwned + Send + 'static {
    /// Signalåç§°
    fn name() -> &'static str;
}

/// Signalæ³¨å†Œè¡¨
pub struct SignalRegistry {
    handlers: Arc<RwLock<HashMap<String, SignalHandler>>>,
    pending: Arc<RwLock<HashMap<String, VecDeque<Value>>>>,
}

type SignalHandler = Box<dyn Fn(Value) -> BoxFuture<'static, Result<(), SignalError>> + Send + Sync>;

impl SignalRegistry {
    /// æ³¨å†ŒSignalå¤„ç†å™¨
    pub fn register<S, F, Fut>(&self, handler: F)
    where
        S: Signal,
        F: Fn(S) -> Fut + Send + Sync + 'static,
        Fut: Future<Output = Result<(), SignalError>> + Send + 'static,
    {
        let boxed: SignalHandler = Box::new(move |value: Value| {
            let signal: S = serde_json::from_value(value).expect("Signal deserialization failed");
            Box::pin(handler(signal))
        });
        
        self.handlers.write().unwrap().insert(S::name().to_string(), boxed);
    }

    /// å‘é€Signal
    pub async fn send<S: Signal>(&self, signal: S) -> Result<(), SignalError> {
        let signal_name = S::name();
        let value = serde_json::to_value(&signal)?;

        // å¦‚æœæœ‰å¤„ç†å™¨ï¼Œç«‹å³å¤„ç†
        if let Some(handler) = self.handlers.read().unwrap().get(signal_name) {
            handler(value).await
        } else {
            // å¦åˆ™åŠ å…¥å¾…å¤„ç†é˜Ÿåˆ—
            self.pending
                .write()
                .unwrap()
                .entry(signal_name.to_string())
                .or_insert_with(VecDeque::new)
                .push_back(value);
            Ok(())
        }
    }

    /// ç­‰å¾…Signal
    pub async fn await_signal<S: Signal>(&self) -> Result<S, SignalError> {
        let signal_name = S::name();
        
        loop {
            // æ£€æŸ¥å¾…å¤„ç†é˜Ÿåˆ—
            if let Some(value) = self.pending
                .write()
                .unwrap()
                .get_mut(signal_name)
                .and_then(|q| q.pop_front())
            {
                return Ok(serde_json::from_value(value)?);
            }

            // ç­‰å¾…æ–°Signal
            tokio::time::sleep(Duration::from_millis(100)).await;
        }
    }
}

/// åœ¨WorkflowContextä¸­ä½¿ç”¨Signal
impl WorkflowContext {
    /// ç­‰å¾…Signal
    pub async fn await_signal<S: Signal>(&self, signal_name: &str) -> Result<S, WorkflowError> {
        self.signals.await_signal().await
            .map_err(|e| WorkflowError::SignalError(e))
    }

    /// å‘é€Signalåˆ°å…¶ä»–å·¥ä½œæµ
    pub async fn signal_workflow<S: Signal>(
        &self,
        workflow_id: &WorkflowId,
        signal: S,
    ) -> Result<(), WorkflowError> {
        // é€šè¿‡å®¢æˆ·ç«¯å‘é€Signal
        self.client.signal_workflow(workflow_id, S::name(), signal).await
    }
}

/// Signalä½¿ç”¨ç¤ºä¾‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ApprovalSignal {
    pub approved: bool,
    pub approver: String,
    pub comment: Option<String>,
}

impl Signal for ApprovalSignal {
    fn name() -> &'static str {
        "approval"
    }
}

// åœ¨å·¥ä½œæµä¸­ä½¿ç”¨
#[workflow]
async fn approval_workflow(ctx: WorkflowContext) -> Result<ApprovalResult> {
    // ç­‰å¾…å®¡æ‰¹Signal
    let approval = ctx.await_signal::<ApprovalSignal>("approval").await?;
    
    if approval.approved {
        Ok(ApprovalResult::Approved {
            approver: approval.approver,
        })
    } else {
        Ok(ApprovalResult::Rejected {
            reason: approval.comment.unwrap_or_default(),
        })
    }
}
```

### 3.2 Queryç³»ç»Ÿè®¾è®¡

```rust
/// Queryå®šä¹‰trait
pub trait Query: Serialize + DeserializeOwned + Send + 'static {
    /// Queryåç§°
    fn name() -> &'static str;
    /// Queryç»“æœç±»å‹
    type Result: Serialize + DeserializeOwned + Send;
}

/// Queryæ³¨å†Œè¡¨
pub struct QueryRegistry {
    handlers: Arc<RwLock<HashMap<String, QueryHandler>>>,
}

type QueryHandler = Box<dyn Fn() -> BoxFuture<'static, Result<Value, QueryError>> + Send + Sync>;

impl QueryRegistry {
    /// æ³¨å†ŒQueryå¤„ç†å™¨
    pub fn register<Q, F, Fut>(&self, handler: F)
    where
        Q: Query,
        F: Fn() -> Fut + Send + Sync + 'static,
        Fut: Future<Output = Result<Q::Result, QueryError>> + Send + 'static,
    {
        let boxed: QueryHandler = Box::new(move || {
            Box::pin(async move {
                let result = handler().await?;
                Ok(serde_json::to_value(&result)?)
            })
        });
        
        self.handlers.write().unwrap().insert(Q::name().to_string(), boxed);
    }

    /// æ‰§è¡ŒQuery
    pub async fn execute<Q: Query>(&self) -> Result<Q::Result, QueryError> {
        let query_name = Q::name();
        
        let handler = self.handlers
            .read()
            .unwrap()
            .get(query_name)
            .ok_or_else(|| QueryError::NotFound(query_name.to_string()))?
            .clone();

        let value = handler().await?;
        Ok(serde_json::from_value(value)?)
    }
}

/// åœ¨WorkflowContextä¸­ä½¿ç”¨Query
impl WorkflowContext {
    /// è®¾ç½®Queryå¤„ç†å™¨
    pub fn set_query_handler<Q, F, Fut>(&self, handler: F)
    where
        Q: Query,
        F: Fn() -> Fut + Send + Sync + 'static,
        Fut: Future<Output = Result<Q::Result, QueryError>> + Send + 'static,
    {
        self.queries.register::<Q, _, _>(handler);
    }

    /// æŸ¥è¯¢å…¶ä»–å·¥ä½œæµ
    pub async fn query_workflow<Q: Query>(
        &self,
        workflow_id: &WorkflowId,
    ) -> Result<Q::Result, WorkflowError> {
        self.client.query_workflow(workflow_id, Q::name()).await
            .map_err(|e| WorkflowError::QueryError(e))
    }
}

/// Queryä½¿ç”¨ç¤ºä¾‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowStatusQuery;

impl Query for WorkflowStatusQuery {
    fn name() -> &'static str {
        "status"
    }
    type Result = WorkflowStatus;
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowStatus {
    pub current_state: String,
    pub progress: f64,
    pub started_at: DateTime<Utc>,
}

// åœ¨å·¥ä½œæµä¸­ä½¿ç”¨
#[workflow]
async fn monitored_workflow(ctx: WorkflowContext) -> Result<Output> {
    let status = Arc::new(RwLock::new(WorkflowStatus {
        current_state: "initializing".to_string(),
        progress: 0.0,
        started_at: Utc::now(),
    }));

    let status_clone = status.clone();
    
    // è®¾ç½®Queryå¤„ç†å™¨
    ctx.set_query_handler::<WorkflowStatusQuery, _, _>(move || {
        let status = status_clone.clone();
        async move {
            Ok(status.read().unwrap().clone())
        }
    });

    // æ‰§è¡Œå·¥ä½œæµé€»è¾‘ï¼Œæ›´æ–°çŠ¶æ€
    *status.write().unwrap() = WorkflowStatus {
        current_state: "processing".to_string(),
        progress: 0.5,
        started_at: Utc::now(),
    };

    // ... æ›´å¤šé€»è¾‘
    
    Ok(Output {})
}
```

---

## 4. äº‹ä»¶æº¯æºå’ŒæŒä¹…åŒ–

### 4.1 äº‹ä»¶å†å²è®¾è®¡

```rust
/// å·¥ä½œæµäº‹ä»¶ - Temporal Event Historyçš„Rustå®ç°
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum WorkflowEvent {
    /// å·¥ä½œæµå¼€å§‹
    WorkflowExecutionStarted {
        workflow_id: WorkflowId,
        workflow_type: String,
        input: Value,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// Activityè°ƒåº¦
    ActivityTaskScheduled {
        activity_id: ActivityId,
        activity_type: String,
        input: Value,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// Activityå¼€å§‹
    ActivityTaskStarted {
        activity_id: ActivityId,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// Activityå®Œæˆ
    ActivityTaskCompleted {
        activity_id: ActivityId,
        result: Value,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// Activityå¤±è´¥
    ActivityTaskFailed {
        activity_id: ActivityId,
        error: String,
        retry_count: u32,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// Timerå¯åŠ¨
    TimerStarted {
        timer_id: TimerId,
        duration: Duration,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// Timerè§¦å‘
    TimerFired {
        timer_id: TimerId,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// Signalæ¥æ”¶
    WorkflowSignalReceived {
        signal_name: String,
        signal_data: Value,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// å­å·¥ä½œæµå¯åŠ¨
    ChildWorkflowExecutionStarted {
        child_workflow_id: WorkflowId,
        workflow_type: String,
        input: Value,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// å·¥ä½œæµå®Œæˆ
    WorkflowExecutionCompleted {
        result: Value,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
    
    /// å·¥ä½œæµå¤±è´¥
    WorkflowExecutionFailed {
        error: String,
        timestamp: DateTime<Utc>,
        event_id: EventId,
    },
}

/// äº‹ä»¶ID
#[derive(Debug, Clone, Copy, Hash, Eq, PartialEq, Serialize, Deserialize)]
pub struct EventId(u64);

/// äº‹ä»¶å†å²
pub struct EventHistory {
    events: Vec<WorkflowEvent>,
    next_event_id: AtomicU64,
}

impl EventHistory {
    /// è¿½åŠ äº‹ä»¶
    pub fn append(&mut self, mut event: WorkflowEvent) -> EventId {
        let event_id = EventId(self.next_event_id.fetch_add(1, Ordering::SeqCst));
        
        // è®¾ç½®äº‹ä»¶ID
        match &mut event {
            WorkflowEvent::WorkflowExecutionStarted { event_id: id, .. } |
            WorkflowEvent::ActivityTaskScheduled { event_id: id, .. } |
            WorkflowEvent::ActivityTaskStarted { event_id: id, .. } |
            WorkflowEvent::ActivityTaskCompleted { event_id: id, .. } |
            WorkflowEvent::ActivityTaskFailed { event_id: id, .. } |
            WorkflowEvent::TimerStarted { event_id: id, .. } |
            WorkflowEvent::TimerFired { event_id: id, .. } |
            WorkflowEvent::WorkflowSignalReceived { event_id: id, .. } |
            WorkflowEvent::ChildWorkflowExecutionStarted { event_id: id, .. } |
            WorkflowEvent::WorkflowExecutionCompleted { event_id: id, .. } |
            WorkflowEvent::WorkflowExecutionFailed { event_id: id, .. } => {
                *id = event_id;
            }
        }
        
        self.events.push(event);
        event_id
    }

    /// è·å–æ‰€æœ‰äº‹ä»¶
    pub fn get_events(&self) -> &[WorkflowEvent] {
        &self.events
    }

    /// ä»äº‹ä»¶é‡å»ºå·¥ä½œæµçŠ¶æ€
    pub fn replay(&self) -> WorkflowReplayState {
        let mut state = WorkflowReplayState::new();
        
        for event in &self.events {
            state.apply_event(event);
        }
        
        state
    }
}

/// å·¥ä½œæµé‡æ”¾çŠ¶æ€
pub struct WorkflowReplayState {
    completed_activities: HashSet<ActivityId>,
    completed_timers: HashSet<TimerId>,
    received_signals: Vec<(String, Value)>,
}

impl WorkflowReplayState {
    pub fn new() -> Self {
        Self {
            completed_activities: HashSet::new(),
            completed_timers: HashSet::new(),
            received_signals: Vec::new(),
        }
    }

    pub fn apply_event(&mut self, event: &WorkflowEvent) {
        match event {
            WorkflowEvent::ActivityTaskCompleted { activity_id, .. } => {
                self.completed_activities.insert(activity_id.clone());
            }
            WorkflowEvent::TimerFired { timer_id, .. } => {
                self.completed_timers.insert(timer_id.clone());
            }
            WorkflowEvent::WorkflowSignalReceived { signal_name, signal_data, .. } => {
                self.received_signals.push((signal_name.clone(), signal_data.clone()));
            }
            _ => {}
        }
    }
}
```

### 4.2 æŒä¹…åŒ–å­˜å‚¨

```rust
/// å·¥ä½œæµå­˜å‚¨trait - Temporal Persistenceçš„RustæŠ½è±¡
#[async_trait]
pub trait WorkflowStorage: Send + Sync {
    /// ä¿å­˜å·¥ä½œæµæ‰§è¡Œ
    async fn save_workflow_execution(
        &self,
        execution: &WorkflowExecution,
        history: &EventHistory,
    ) -> Result<(), StorageError>;

    /// åŠ è½½å·¥ä½œæµæ‰§è¡Œ
    async fn load_workflow_execution(
        &self,
        workflow_id: &WorkflowId,
    ) -> Result<(WorkflowExecution, EventHistory), StorageError>;

    /// è¿½åŠ äº‹ä»¶
    async fn append_event(
        &self,
        workflow_id: &WorkflowId,
        event: WorkflowEvent,
    ) -> Result<EventId, StorageError>;

    /// è·å–äº‹ä»¶å†å²
    async fn get_event_history(
        &self,
        workflow_id: &WorkflowId,
        from_event_id: Option<EventId>,
    ) -> Result<Vec<WorkflowEvent>, StorageError>;

    /// ä¿å­˜Activityå¿ƒè·³
    async fn save_activity_heartbeat(
        &self,
        activity_id: &ActivityId,
        details: Value,
    ) -> Result<(), StorageError>;
}

/// PostgreSQLå­˜å‚¨å®ç°
pub struct PostgresWorkflowStorage {
    pool: PgPool,
}

#[async_trait]
impl WorkflowStorage for PostgresWorkflowStorage {
    async fn save_workflow_execution(
        &self,
        execution: &WorkflowExecution,
        history: &EventHistory,
    ) -> Result<(), StorageError> {
        let mut tx = self.pool.begin().await?;

        // ä¿å­˜å·¥ä½œæµæ‰§è¡Œè®°å½•
        sqlx::query!(
            r#"
            INSERT INTO workflow_executions (workflow_id, run_id, status, created_at)
            VALUES ($1, $2, $3, $4)
            ON CONFLICT (workflow_id, run_id) DO UPDATE
            SET status = $3
            "#,
            execution.workflow_id.0,
            execution.run_id.0,
            "running",
            Utc::now(),
        )
        .execute(&mut *tx)
        .await?;

        // ä¿å­˜äº‹ä»¶å†å²
        for event in history.get_events() {
            let event_json = serde_json::to_value(event)?;
            sqlx::query!(
                r#"
                INSERT INTO workflow_events (workflow_id, run_id, event_id, event_data, created_at)
                VALUES ($1, $2, $3, $4, $5)
                "#,
                execution.workflow_id.0,
                execution.run_id.0,
                event.event_id().0 as i64,
                event_json,
                Utc::now(),
            )
            .execute(&mut *tx)
            .await?;
        }

        tx.commit().await?;
        Ok(())
    }

    async fn load_workflow_execution(
        &self,
        workflow_id: &WorkflowId,
    ) -> Result<(WorkflowExecution, EventHistory), StorageError> {
        // åŠ è½½å·¥ä½œæµæ‰§è¡Œ
        let exec_row = sqlx::query!(
            r#"
            SELECT workflow_id, run_id
            FROM workflow_executions
            WHERE workflow_id = $1
            ORDER BY created_at DESC
            LIMIT 1
            "#,
            workflow_id.0,
        )
        .fetch_one(&self.pool)
        .await?;

        let execution = WorkflowExecution {
            workflow_id: WorkflowId(exec_row.workflow_id),
            run_id: RunId(Uuid::parse_str(&exec_row.run_id)?),
        };

        // åŠ è½½äº‹ä»¶å†å²
        let event_rows = sqlx::query!(
            r#"
            SELECT event_data
            FROM workflow_events
            WHERE workflow_id = $1 AND run_id = $2
            ORDER BY event_id ASC
            "#,
            execution.workflow_id.0,
            execution.run_id.0.to_string(),
        )
        .fetch_all(&self.pool)
        .await?;

        let mut history = EventHistory::new();
        for row in event_rows {
            let event: WorkflowEvent = serde_json::from_value(row.event_data)?;
            history.append(event);
        }

        Ok((execution, history))
    }

    // ... å…¶ä»–æ–¹æ³•å®ç°
}
```

---

## 5. Workerå®ç°

### 5.1 WorkflowWorkerè®¾è®¡

```rust
/// å·¥ä½œæµWorker - Temporal Workerçš„Rustå®ç°
pub struct WorkflowWorker {
    /// Workeré…ç½®
    config: WorkerConfig,
    /// ä»»åŠ¡é˜Ÿåˆ—
    task_queue: String,
    /// å·²æ³¨å†Œçš„å·¥ä½œæµ
    workflows: Arc<RwLock<HashMap<String, WorkflowFactory>>>,
    /// å·²æ³¨å†Œçš„Activities
    activities: Arc<RwLock<HashMap<String, ActivityFactory>>>,
    /// å­˜å‚¨
    storage: Arc<dyn WorkflowStorage>,
    /// å–æ¶ˆä»¤ç‰Œ
    cancellation: CancellationToken,
}

type WorkflowFactory = Arc<dyn Fn(WorkflowContext, Value) -> BoxFuture<'static, Result<Value, WorkflowError>> + Send + Sync>;
type ActivityFactory = Arc<dyn Fn(ActivityContext, Value) -> BoxFuture<'static, Result<Value, ActivityError>> + Send + Sync>;

/// Workeré…ç½®
#[derive(Debug, Clone)]
pub struct WorkerConfig {
    /// æœ€å¤§å¹¶å‘å·¥ä½œæµæ‰§è¡Œæ•°
    pub max_concurrent_workflow_executions: usize,
    /// æœ€å¤§å¹¶å‘Activityæ‰§è¡Œæ•°
    pub max_concurrent_activity_executions: usize,
    /// Workerèº«ä»½
    pub identity: String,
}

impl WorkflowWorker {
    /// åˆ›å»ºæ–°Worker
    pub fn new(
        task_queue: String,
        storage: Arc<dyn WorkflowStorage>,
        config: WorkerConfig,
    ) -> Self {
        Self {
            config,
            task_queue,
            workflows: Arc::new(RwLock::new(HashMap::new())),
            activities: Arc::new(RwLock::new(HashMap::new())),
            storage,
            cancellation: CancellationToken::new(),
        }
    }

    /// æ³¨å†Œå·¥ä½œæµ
    pub fn register_workflow<F, Fut, I, O>(
        &mut self,
        workflow_type: String,
        factory: F,
    ) where
        F: Fn(WorkflowContext, I) -> Fut + Send + Sync + 'static,
        Fut: Future<Output = Result<O, WorkflowError>> + Send + 'static,
        I: DeserializeOwned + Send + 'static,
        O: Serialize + Send + 'static,
    {
        let factory: WorkflowFactory = Arc::new(move |ctx, input| {
            let input: I = serde_json::from_value(input).expect("Workflow input deserialization failed");
            Box::pin(async move {
                let output = factory(ctx, input).await?;
                Ok(serde_json::to_value(&output)?)
            })
        });

        self.workflows.write().unwrap().insert(workflow_type, factory);
    }

    /// æ³¨å†ŒActivity
    pub fn register_activity<F, Fut, I, O>(
        &mut self,
        activity_type: String,
        factory: F,
    ) where
        F: Fn(ActivityContext, I) -> Fut + Send + Sync + 'static,
        Fut: Future<Output = Result<O, ActivityError>> + Send + 'static,
        I: DeserializeOwned + Send + 'static,
        O: Serialize + Send + 'static,
    {
        let factory: ActivityFactory = Arc::new(move |ctx, input| {
            let input: I = serde_json::from_value(input).expect("Activity input deserialization failed");
            Box::pin(async move {
                let output = factory(ctx, input).await?;
                Ok(serde_json::to_value(&output)?)
            })
        });

        self.activities.write().unwrap().insert(activity_type, factory);
    }

    /// å¯åŠ¨Worker
    pub async fn start(self: Arc<Self>) -> Result<(), WorkerError> {
        let workflow_worker = self.clone();
        let activity_worker = self.clone();

        // å¯åŠ¨å·¥ä½œæµè½®è¯¢
        let workflow_handle = tokio::spawn(async move {
            workflow_worker.poll_workflow_tasks().await
        });

        // å¯åŠ¨Activityè½®è¯¢
        let activity_handle = tokio::spawn(async move {
            activity_worker.poll_activity_tasks().await
        });

        // ç­‰å¾…å®Œæˆæˆ–å–æ¶ˆ
        tokio::select! {
            _ = workflow_handle => {},
            _ = activity_handle => {},
            _ = self.cancellation.cancelled() => {},
        }

        Ok(())
    }

    /// è½®è¯¢å·¥ä½œæµä»»åŠ¡
    async fn poll_workflow_tasks(&self) -> Result<(), WorkerError> {
        let semaphore = Arc::new(Semaphore::new(self.config.max_concurrent_workflow_executions));

        loop {
            if self.cancellation.is_cancelled() {
                break;
            }

            // è·å–è®¸å¯
            let permit = semaphore.clone().acquire_owned().await?;

            // è½®è¯¢ä»»åŠ¡
            match self.poll_workflow_task_once().await {
                Ok(Some(task)) => {
                    let worker = self.clone();
                    tokio::spawn(async move {
                        let _permit = permit;
                        worker.execute_workflow_task(task).await.ok();
                    });
                }
                Ok(None) => {
                    // æ²¡æœ‰ä»»åŠ¡ï¼Œç­‰å¾…
                    tokio::time::sleep(Duration::from_millis(100)).await;
                }
                Err(e) => {
                    tracing::error!("Failed to poll workflow task: {}", e);
                    tokio::time::sleep(Duration::from_secs(1)).await;
                }
            }
        }

        Ok(())
    }

    /// æ‰§è¡Œå·¥ä½œæµä»»åŠ¡
    async fn execute_workflow_task(&self, task: WorkflowTask) -> Result<(), WorkflowError> {
        // åˆ›å»ºå·¥ä½œæµä¸Šä¸‹æ–‡
        let ctx = WorkflowContext::new(
            task.workflow_execution.clone(),
            task.workflow_type.clone(),
            self.task_queue.clone(),
            self.storage.clone(),
        );

        // è·å–å·¥ä½œæµå·¥å‚
        let factory = self.workflows
            .read()
            .unwrap()
            .get(&task.workflow_type)
            .ok_or_else(|| WorkflowError::WorkflowNotRegistered(task.workflow_type.clone()))?
            .clone();

        // æ‰§è¡Œå·¥ä½œæµ
        let result = factory(ctx, task.input).await;

        // å¤„ç†ç»“æœ
        match result {
            Ok(output) => {
                // è®°å½•å®Œæˆäº‹ä»¶
                self.storage.append_event(
                    &task.workflow_execution.workflow_id,
                    WorkflowEvent::WorkflowExecutionCompleted {
                        result: output,
                        timestamp: Utc::now(),
                        event_id: EventId(0), // Will be set by append_event
                    },
                ).await?;
            }
            Err(error) => {
                // è®°å½•å¤±è´¥äº‹ä»¶
                self.storage.append_event(
                    &task.workflow_execution.workflow_id,
                    WorkflowEvent::WorkflowExecutionFailed {
                        error: error.to_string(),
                        timestamp: Utc::now(),
                        event_id: EventId(0),
                    },
                ).await?;
            }
        }

        Ok(())
    }

    // ... Activityè½®è¯¢å’Œæ‰§è¡Œç±»ä¼¼
}
```

---

## 6. å®¢æˆ·ç«¯å®ç°

### 6.1 WorkflowClientè®¾è®¡

```rust
/// å·¥ä½œæµå®¢æˆ·ç«¯ - Temporal Clientçš„Rustå®ç°
pub struct WorkflowClient {
    /// å­˜å‚¨
    storage: Arc<dyn WorkflowStorage>,
    /// ä»»åŠ¡åˆ†å‘å™¨
    task_dispatcher: Arc<TaskDispatcher>,
}

impl WorkflowClient {
    /// å¯åŠ¨å·¥ä½œæµ
    pub async fn start_workflow<W, I, O>(
        &self,
        workflow_id: WorkflowId,
        task_queue: String,
        input: I,
        options: StartWorkflowOptions,
    ) -> Result<WorkflowHandle<O>, ClientError>
    where
        W: Workflow<Input = I, Output = O>,
        I: Serialize + Send + 'static,
        O: DeserializeOwned + Send + 'static,
    {
        // åˆ›å»ºå·¥ä½œæµæ‰§è¡Œ
        let execution = WorkflowExecution {
            workflow_id: workflow_id.clone(),
            run_id: RunId(Uuid::new_v4()),
        };

        // è®°å½•å¯åŠ¨äº‹ä»¶
        let event = WorkflowEvent::WorkflowExecutionStarted {
            workflow_id: workflow_id.clone(),
            workflow_type: W::name().to_string(),
            input: serde_json::to_value(&input)?,
            timestamp: Utc::now(),
            event_id: EventId(0),
        };

        let mut history = EventHistory::new();
        history.append(event);

        // ä¿å­˜åˆ°å­˜å‚¨
        self.storage.save_workflow_execution(&execution, &history).await?;

        // åˆ†å‘ä»»åŠ¡åˆ°Worker
        self.task_dispatcher.dispatch_workflow_task(WorkflowTask {
            workflow_execution: execution.clone(),
            workflow_type: W::name().to_string(),
            task_queue,
            input: serde_json::to_value(&input)?,
        }).await?;

        // è¿”å›Handle
        Ok(WorkflowHandle::new(execution, self.storage.clone()))
    }

    /// å‘é€Signal
    pub async fn signal_workflow<S: Signal>(
        &self,
        workflow_id: &WorkflowId,
        signal: S,
    ) -> Result<(), ClientError> {
        // è®°å½•Signaläº‹ä»¶
        let event = WorkflowEvent::WorkflowSignalReceived {
            signal_name: S::name().to_string(),
            signal_data: serde_json::to_value(&signal)?,
            timestamp: Utc::now(),
            event_id: EventId(0),
        };

        self.storage.append_event(workflow_id, event).await?;
        Ok(())
    }

    /// æŸ¥è¯¢å·¥ä½œæµ
    pub async fn query_workflow<Q: Query>(
        &self,
        workflow_id: &WorkflowId,
        query_name: &str,
    ) -> Result<Q::Result, ClientError> {
        // å‘Workerå‘é€æŸ¥è¯¢è¯·æ±‚
        // è¿™é‡Œéœ€è¦ä¸Workeré€šä¿¡
        // ç®€åŒ–å®ç°ï¼Œå®é™…éœ€è¦RPCæœºåˆ¶
        todo!("Query implementation requires RPC")
    }

    /// è·å–å·¥ä½œæµHandle
    pub fn get_workflow_handle<O: DeserializeOwned>(
        &self,
        workflow_id: WorkflowId,
        run_id: RunId,
    ) -> WorkflowHandle<O> {
        WorkflowHandle::new(
            WorkflowExecution { workflow_id, run_id },
            self.storage.clone(),
        )
    }
}

/// å·¥ä½œæµHandle
pub struct WorkflowHandle<O> {
    execution: WorkflowExecution,
    storage: Arc<dyn WorkflowStorage>,
    _phantom: PhantomData<O>,
}

impl<O: DeserializeOwned> WorkflowHandle<O> {
    fn new(execution: WorkflowExecution, storage: Arc<dyn WorkflowStorage>) -> Self {
        Self {
            execution,
            storage,
            _phantom: PhantomData,
        }
    }

    /// è·å–å·¥ä½œæµID
    pub fn workflow_id(&self) -> &WorkflowId {
        &self.execution.workflow_id
    }

    /// è·å–è¿è¡ŒID
    pub fn run_id(&self) -> &RunId {
        &self.execution.run_id
    }

    /// ç­‰å¾…å®Œæˆ
    pub async fn get_result(&self) -> Result<O, WorkflowError> {
        loop {
            // åŠ è½½äº‹ä»¶å†å²
            let (_, history) = self.storage
                .load_workflow_execution(&self.execution.workflow_id)
                .await?;

            // æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if let Some(last_event) = history.get_events().last() {
                match last_event {
                    WorkflowEvent::WorkflowExecutionCompleted { result, .. } => {
                        return Ok(serde_json::from_value(result.clone())?);
                    }
                    WorkflowEvent::WorkflowExecutionFailed { error, .. } => {
                        return Err(WorkflowError::ExecutionFailed(error.clone()));
                    }
                    _ => {}
                }
            }

            // ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
            tokio::time::sleep(Duration::from_millis(100)).await;
        }
    }

    /// å‘é€Signal
    pub async fn signal<S: Signal>(&self, signal: S) -> Result<(), WorkflowError> {
        let event = WorkflowEvent::WorkflowSignalReceived {
            signal_name: S::name().to_string(),
            signal_data: serde_json::to_value(&signal)?,
            timestamp: Utc::now(),
            event_id: EventId(0),
        };

        self.storage.append_event(&self.execution.workflow_id, event).await?;
        Ok(())
    }

    /// å–æ¶ˆå·¥ä½œæµ
    pub async fn cancel(&self) -> Result<(), WorkflowError> {
        // å®ç°å–æ¶ˆé€»è¾‘
        todo!("Cancel workflow")
    }
}
```

---

## 7. å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

### 7.1 åŸºæœ¬ä½¿ç”¨æµç¨‹

```rust
use temporal_rust::prelude::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 1. è®¾ç½®å­˜å‚¨
    let storage = Arc::new(PostgresWorkflowStorage::new("postgres://...").await?);

    // 2. åˆ›å»ºWorker
    let mut worker = WorkflowWorker::new(
        "my-task-queue".to_string(),
        storage.clone(),
        WorkerConfig::default(),
    );

    // 3. æ³¨å†Œå·¥ä½œæµå’ŒActivities
    worker.register_workflow(
        "OrderProcessingWorkflow".to_string(),
        order_processing_workflow,
    );
    
    worker.register_activity(
        "ValidateOrderActivity".to_string(),
        validate_order_activity,
    );
    
    worker.register_activity(
        "ProcessPaymentActivity".to_string(),
        process_payment_activity,
    );

    // 4. å¯åŠ¨Worker (åœ¨åå°çº¿ç¨‹)
    let worker = Arc::new(worker);
    let worker_handle = tokio::spawn({
        let worker = worker.clone();
        async move {
            worker.start().await
        }
    });

    // 5. åˆ›å»ºå®¢æˆ·ç«¯
    let client = WorkflowClient::new(storage.clone());

    // 6. å¯åŠ¨å·¥ä½œæµ
    let handle = client.start_workflow::<OrderProcessingWorkflow, _, _>(
        WorkflowId(format!("order-{}", Uuid::new_v4())),
        "my-task-queue".to_string(),
        OrderInput {
            order_id: "ORDER-123".to_string(),
            customer_id: "CUST-456".to_string(),
            items: vec![/* ... */],
            payment_info: PaymentInfo {/* ... */},
        },
        StartWorkflowOptions::default(),
    ).await?;

    println!("Started workflow: {:?}", handle.workflow_id());

    // 7. å‘é€Signal (å¯é€‰)
    tokio::time::sleep(Duration::from_secs(5)).await;
    handle.signal(ApprovalSignal {
        approved: true,
        approver: "admin".to_string(),
        comment: Some("Approved".to_string()),
    }).await?;

    // 8. ç­‰å¾…ç»“æœ
    let result = handle.get_result().await?;
    println!("Workflow completed: {:?}", result);

    Ok(())
}
```

---

## 8. æ–‡æ¡£ç»“æ„è§„åˆ’

å»ºè®®çš„æ–‡æ¡£ç›®å½•ç»“æ„ï¼š

```text
workflow/docs/
â”œâ”€â”€ temporal_rust/                    # åŸºäºTemporalçš„Rustå®ç°
â”‚   â”œâ”€â”€ 01_overview.md               # æ¦‚è¿°
â”‚   â”œâ”€â”€ 02_architecture.md           # æ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ 03_workflow_definition.md    # å·¥ä½œæµå®šä¹‰
â”‚   â”œâ”€â”€ 04_activity_definition.md    # Activityå®šä¹‰
â”‚   â”œâ”€â”€ 05_signals_and_queries.md    # Signalå’ŒQuery
â”‚   â”œâ”€â”€ 06_event_sourcing.md         # äº‹ä»¶æº¯æº
â”‚   â”œâ”€â”€ 07_worker_implementation.md  # Workerå®ç°
â”‚   â”œâ”€â”€ 08_client_usage.md           # å®¢æˆ·ç«¯ä½¿ç”¨
â”‚   â”œâ”€â”€ 09_testing.md                # æµ‹è¯•
â”‚   â””â”€â”€ 10_deployment.md             # éƒ¨ç½²
â”œâ”€â”€ api_reference/                    # APIå‚è€ƒ
â”‚   â”œâ”€â”€ workflow_context.md
â”‚   â”œâ”€â”€ activity_context.md
â”‚   â”œâ”€â”€ workflow_client.md
â”‚   â””â”€â”€ worker_config.md
â”œâ”€â”€ examples/                         # ç¤ºä¾‹
â”‚   â”œâ”€â”€ basic_workflow.md
â”‚   â”œâ”€â”€ saga_pattern.md
â”‚   â”œâ”€â”€ signal_query_example.md
â”‚   â””â”€â”€ child_workflow_example.md
â””â”€â”€ deprecated/                       # è¿‡æ—¶æ–‡æ¡£(è¿ç§»æ—§æ–‡æ¡£åˆ°è¿™é‡Œ)
    â”œâ”€â”€ old_design/
    â””â”€â”€ legacy_examples/
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0-temporal-native  
**æœ€åæ›´æ–°**: 2025-10-26  
**ä½œè€…**: workflow_rustå›¢é˜Ÿ
