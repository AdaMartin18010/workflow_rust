# Temporalæ¡†æ¶å¯¹é½å®æ–½è·¯çº¿å›¾

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æ˜¯ã€ŠTemporalæ¡†æ¶å¯¹æ ‡åˆ†æä¸æœ¬é¡¹ç›®ä½¿ç”¨æ¢³ç†ã€‹çš„å®æ–½è®¡åˆ’ï¼Œè¯¦ç»†è§„åˆ’äº†å¦‚ä½•å°†æœ¬é¡¹ç›®çš„å·¥ä½œæµèƒ½åŠ›å‘Temporalæ¡†æ¶å¯¹é½çš„å…·ä½“æ­¥éª¤ã€‚

**ç›®æ ‡**: åœ¨ä¿æŒRustè¯­è¨€ä¼˜åŠ¿çš„åŒæ—¶ï¼Œæä¾›ç±»Temporalçš„å¼€å‘ä½“éªŒå’Œä¼ä¸šçº§ç‰¹æ€§ã€‚

---

## ğŸ¯ æ€»ä½“ç›®æ ‡

### çŸ­æœŸç›®æ ‡ (Q1 2025 - 3ä¸ªæœˆ)

- å®ç°ActivityæŠ½è±¡å±‚
- æ·»åŠ Signalå’ŒQueryæœºåˆ¶
- å¢å¼ºæŒä¹…åŒ–èƒ½åŠ›ï¼ˆäº‹ä»¶æº¯æºï¼‰
- è¾¾åˆ°60%+ Temporalç‰¹æ€§å¯¹é½

### ä¸­æœŸç›®æ ‡ (Q2-Q3 2025 - 6ä¸ªæœˆ)

- å®ç°ç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿ
- æ·»åŠ å­å·¥ä½œæµæ”¯æŒ
- å®Œå–„å¯è§‚æµ‹æ€§
- è¾¾åˆ°75%+ Temporalç‰¹æ€§å¯¹é½

### é•¿æœŸç›®æ ‡ (Q4 2025 - 12ä¸ªæœˆ)

- åˆ†å¸ƒå¼éƒ¨ç½²èƒ½åŠ›
- ä¸Temporaläº’æ“ä½œ
- ç”Ÿäº§å°±ç»ª
- è¾¾åˆ°85%+ æ ¸å¿ƒç‰¹æ€§å¯¹é½

---

## ğŸ“… è¯¦ç»†å®æ–½è®¡åˆ’

## ç¬¬ä¸€é˜¶æ®µ: æ ¸å¿ƒèƒ½åŠ›è¡¥é½ (Week 1-12)

### Week 1-4: ActivityæŠ½è±¡å±‚ ğŸ”´

#### ä»»åŠ¡1.1: è®¾è®¡Activity API

**ä¼˜å…ˆçº§**: ğŸ”´ P0  
**ä¼°ç®—å·¥æ—¶**: 3å¤©  
**è´Ÿè´£äºº**: æ ¸å¿ƒå›¢é˜Ÿ

**è®¾è®¡è¦ç‚¹:**

```rust
// src/activity/mod.rs

#[async_trait]
pub trait Activity: Send + Sync {
    /// Activityçš„è¾“å…¥ç±»å‹
    type Input: DeserializeOwned + Send;
    /// Activityçš„è¾“å‡ºç±»å‹
    type Output: Serialize + Send;
    /// Activityçš„é”™è¯¯ç±»å‹
    type Error: std::error::Error + Send;
    
    /// Activityçš„å”¯ä¸€åç§°
    fn name(&self) -> &str;
    
    /// æ‰§è¡ŒActivity
    async fn execute(&self, input: Self::Input) -> Result<Self::Output, Self::Error>;
    
    /// é‡è¯•ç­–ç•¥ï¼ˆå¯é€‰ï¼‰
    fn retry_policy(&self) -> Option<RetryPolicy> {
        Some(RetryPolicy::default())
    }
    
    /// æ‰§è¡Œè¶…æ—¶ï¼ˆå¯é€‰ï¼‰
    fn timeout(&self) -> Option<Duration> {
        Some(Duration::from_secs(60))
    }
    
    /// æ˜¯å¦å¹‚ç­‰
    fn is_idempotent(&self) -> bool {
        false
    }
}

/// é‡è¯•ç­–ç•¥
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RetryPolicy {
    /// æœ€å¤§é‡è¯•æ¬¡æ•°
    pub max_attempts: u32,
    /// åˆå§‹é‡è¯•é—´éš”
    pub initial_interval: Duration,
    /// æœ€å¤§é‡è¯•é—´éš”
    pub max_interval: Duration,
    /// é€€é¿ç³»æ•°
    pub backoff_coefficient: f64,
    /// å¯é‡è¯•çš„é”™è¯¯ç±»å‹
    pub retryable_errors: Vec<String>,
}

impl Default for RetryPolicy {
    fn default() -> Self {
        Self {
            max_attempts: 3,
            initial_interval: Duration::from_secs(1),
            max_interval: Duration::from_secs(60),
            backoff_coefficient: 2.0,
            retryable_errors: vec![],
        }
    }
}
```

**äº¤ä»˜ç‰©:**

- [ ] Activity traitå®šä¹‰
- [ ] RetryPolicyå®ç°
- [ ] å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡>80%ï¼‰
- [ ] è®¾è®¡æ–‡æ¡£

#### ä»»åŠ¡1.2: å®ç°ActivityExecutor

**ä¼˜å…ˆçº§**: ğŸ”´ P0  
**ä¼°ç®—å·¥æ—¶**: 5å¤©  

```rust
// src/activity/executor.rs

pub struct ActivityExecutor {
    /// æ³¨å†Œçš„Activity
    activities: Arc<RwLock<HashMap<String, Arc<dyn DynActivity>>>>,
    /// æ‰§è¡Œå†å²
    history: Arc<Mutex<Vec<ActivityExecution>>>,
    /// æ€§èƒ½ç›‘æ§
    metrics: Arc<ActivityMetrics>,
}

impl ActivityExecutor {
    pub fn new() -> Self {
        Self {
            activities: Arc::new(RwLock::new(HashMap::new())),
            history: Arc::new(Mutex::new(Vec::new())),
            metrics: Arc::new(ActivityMetrics::new()),
        }
    }
    
    /// æ³¨å†ŒActivity
    pub fn register<A>(&self, activity: A) 
    where 
        A: Activity + 'static,
        A::Input: DeserializeOwned,
        A::Output: Serialize,
    {
        let name = activity.name().to_string();
        let boxed: Arc<dyn DynActivity> = Arc::new(ActivityAdapter::new(activity));
        self.activities.write().unwrap().insert(name, boxed);
    }
    
    /// æ‰§è¡ŒActivityï¼ˆå¸¦é‡è¯•ï¼‰
    pub async fn execute_with_retry(
        &self,
        activity_name: &str,
        input: Value,
    ) -> Result<Value, ActivityError> {
        let activity = self.activities.read().unwrap()
            .get(activity_name)
            .ok_or(ActivityError::NotFound(activity_name.to_string()))?
            .clone();
        
        let policy = activity.retry_policy()
            .unwrap_or_else(RetryPolicy::default);
        
        let mut attempt = 0;
        let mut interval = policy.initial_interval;
        
        loop {
            attempt += 1;
            let start_time = Instant::now();
            
            // æ‰§è¡ŒActivity
            let result = tokio::time::timeout(
                activity.timeout().unwrap_or(Duration::from_secs(60)),
                activity.execute_dyn(input.clone())
            ).await;
            
            // è®°å½•æŒ‡æ ‡
            let duration = start_time.elapsed();
            self.metrics.record_execution(activity_name, attempt, duration);
            
            match result {
                Ok(Ok(output)) => {
                    // æˆåŠŸ
                    self.record_success(activity_name, attempt, duration).await;
                    return Ok(output);
                }
                Ok(Err(err)) if attempt >= policy.max_attempts => {
                    // è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                    self.record_failure(activity_name, attempt, &err).await;
                    return Err(ActivityError::MaxAttemptsExceeded(Box::new(err)));
                }
                Ok(Err(err)) if self.is_retryable(&err, &policy) => {
                    // å¯é‡è¯•é”™è¯¯
                    tracing::warn!(
                        activity = activity_name,
                        attempt = attempt,
                        error = %err,
                        "Activity execution failed, retrying..."
                    );
                    
                    tokio::time::sleep(interval).await;
                    interval = std::cmp::min(
                        Duration::from_secs_f64(
                            interval.as_secs_f64() * policy.backoff_coefficient
                        ),
                        policy.max_interval,
                    );
                }
                Ok(Err(err)) => {
                    // ä¸å¯é‡è¯•é”™è¯¯
                    self.record_failure(activity_name, attempt, &err).await;
                    return Err(ActivityError::NonRetryable(Box::new(err)));
                }
                Err(_) => {
                    // è¶…æ—¶
                    if attempt >= policy.max_attempts {
                        self.record_timeout(activity_name, attempt).await;
                        return Err(ActivityError::Timeout);
                    }
                    
                    tracing::warn!(
                        activity = activity_name,
                        attempt = attempt,
                        "Activity execution timeout, retrying..."
                    );
                    
                    tokio::time::sleep(interval).await;
                    interval = std::cmp::min(
                        Duration::from_secs_f64(
                            interval.as_secs_f64() * policy.backoff_coefficient
                        ),
                        policy.max_interval,
                    );
                }
            }
        }
    }
    
    fn is_retryable(&self, error: &dyn std::error::Error, policy: &RetryPolicy) -> bool {
        if policy.retryable_errors.is_empty() {
            // å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œé»˜è®¤æ‰€æœ‰é”™è¯¯éƒ½å¯é‡è¯•
            return true;
        }
        
        let error_str = error.to_string();
        policy.retryable_errors.iter()
            .any(|pattern| error_str.contains(pattern))
    }
    
    async fn record_success(&self, name: &str, attempts: u32, duration: Duration) {
        let mut history = self.history.lock().unwrap();
        history.push(ActivityExecution {
            name: name.to_string(),
            attempts,
            duration,
            status: ExecutionStatus::Success,
            timestamp: chrono::Utc::now(),
        });
    }
    
    async fn record_failure(&self, name: &str, attempts: u32, error: &dyn std::error::Error) {
        let mut history = self.history.lock().unwrap();
        history.push(ActivityExecution {
            name: name.to_string(),
            attempts,
            duration: Duration::ZERO,
            status: ExecutionStatus::Failed(error.to_string()),
            timestamp: chrono::Utc::now(),
        });
    }
    
    async fn record_timeout(&self, name: &str, attempts: u32) {
        let mut history = self.history.lock().unwrap();
        history.push(ActivityExecution {
            name: name.to_string(),
            attempts,
            duration: Duration::ZERO,
            status: ExecutionStatus::Timeout,
            timestamp: chrono::Utc::now(),
        });
    }
}

/// æ‰§è¡Œå†å²è®°å½•
#[derive(Debug, Clone)]
struct ActivityExecution {
    name: String,
    attempts: u32,
    duration: Duration,
    status: ExecutionStatus,
    timestamp: chrono::DateTime<chrono::Utc>,
}

#[derive(Debug, Clone)]
enum ExecutionStatus {
    Success,
    Failed(String),
    Timeout,
}

/// æ€§èƒ½æŒ‡æ ‡
struct ActivityMetrics {
    executions: Arc<Mutex<HashMap<String, Vec<Duration>>>>,
}

impl ActivityMetrics {
    fn new() -> Self {
        Self {
            executions: Arc::new(Mutex::new(HashMap::new())),
        }
    }
    
    fn record_execution(&self, name: &str, _attempt: u32, duration: Duration) {
        let mut executions = self.executions.lock().unwrap();
        executions.entry(name.to_string())
            .or_insert_with(Vec::new)
            .push(duration);
            
        // åŒæ—¶è®°å½•åˆ°metricsç³»ç»Ÿ
        metrics::histogram!("activity_duration_seconds", "name" => name.to_string())
            .record(duration.as_secs_f64());
    }
}
```

**äº¤ä»˜ç‰©:**

- [ ] ActivityExecutorå®ç°
- [ ] é‡è¯•é€»è¾‘å®ç°
- [ ] è¶…æ—¶æ§åˆ¶
- [ ] æ€§èƒ½ç›‘æ§é›†æˆ
- [ ] é›†æˆæµ‹è¯•

#### ä»»åŠ¡1.3: ä¸WorkflowEngineé›†æˆ

**ä¼˜å…ˆçº§**: ğŸ”´ P0  
**ä¼°ç®—å·¥æ—¶**: 3å¤©  

```rust
// src/engine.rs (ä¿®æ”¹)

impl WorkflowEngine {
    /// æ·»åŠ Activityæ‰§è¡Œå™¨å­—æ®µ
    activity_executor: Option<Arc<ActivityExecutor>>,
    
    /// è®¾ç½®Activityæ‰§è¡Œå™¨
    pub fn with_activity_executor(mut self, executor: ActivityExecutor) -> Self {
        self.activity_executor = Some(Arc::new(executor));
        self
    }
    
    /// æ‰§è¡ŒActivity
    pub async fn execute_activity(
        &self,
        instance_id: &str,
        activity_name: &str,
        input: Value,
    ) -> Result<Value, WorkflowError> {
        let executor = self.activity_executor.as_ref()
            .ok_or(WorkflowError::ActivityExecutorNotConfigured)?;
        
        // æ‰§è¡ŒActivity
        let result = executor.execute_with_retry(activity_name, input).await
            .map_err(|e| WorkflowError::ActivityExecutionFailed(e.to_string()))?;
        
        // æ›´æ–°å·¥ä½œæµçŠ¶æ€
        // ...
        
        Ok(result)
    }
}
```

**äº¤ä»˜ç‰©:**

- [ ] WorkflowEngineé›†æˆ
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•
- [ ] ç¤ºä¾‹ä»£ç 
- [ ] æ–‡æ¡£æ›´æ–°

### Week 5-8: Signalä¸Queryæœºåˆ¶ ğŸ”´

#### ä»»åŠ¡2.1: Signalæœºåˆ¶è®¾è®¡ä¸å®ç°

**ä¼˜å…ˆçº§**: ğŸ”´ P0  
**ä¼°ç®—å·¥æ—¶**: 5å¤©  

```rust
// src/signal.rs

/// Signalå¤„ç†å™¨trait
#[async_trait]
pub trait SignalHandler: Send + Sync {
    /// Signalæ•°æ®ç±»å‹
    type Data: DeserializeOwned + Send;
    
    /// å¤„ç†Signal
    async fn handle(&mut self, data: Self::Data) -> Result<(), SignalError>;
}

/// Signalç®¡ç†å™¨
pub struct SignalManager {
    /// æ¯ä¸ªå·¥ä½œæµå®ä¾‹çš„Signalé€šé“
    channels: Arc<RwLock<HashMap<String, SignalChannel>>>,
}

struct SignalChannel {
    /// Signalé˜Ÿåˆ—
    queue: Arc<Mutex<VecDeque<SignalEnvelope>>>,
    /// Signalå¤„ç†å™¨
    handlers: HashMap<String, Box<dyn DynSignalHandler>>,
    /// å”¤é†’é€šçŸ¥
    waker: Arc<Notify>,
}

#[derive(Clone)]
struct SignalEnvelope {
    signal_name: String,
    data: Value,
    timestamp: chrono::DateTime<chrono::Utc>,
}

impl SignalManager {
    pub fn new() -> Self {
        Self {
            channels: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    /// æ³¨å†ŒSignalå¤„ç†å™¨
    pub fn register_handler<H>(
        &self,
        instance_id: &str,
        signal_name: &str,
        handler: H,
    ) where
        H: SignalHandler + 'static,
    {
        let mut channels = self.channels.write().unwrap();
        let channel = channels.entry(instance_id.to_string())
            .or_insert_with(|| SignalChannel {
                queue: Arc::new(Mutex::new(VecDeque::new())),
                handlers: HashMap::new(),
                waker: Arc::new(Notify::new()),
            });
        
        channel.handlers.insert(
            signal_name.to_string(),
            Box::new(SignalHandlerAdapter::new(handler))
        );
    }
    
    /// å‘é€Signal
    pub async fn send_signal(
        &self,
        instance_id: &str,
        signal_name: &str,
        data: Value,
    ) -> Result<(), SignalError> {
        let channels = self.channels.read().unwrap();
        let channel = channels.get(instance_id)
            .ok_or(SignalError::InstanceNotFound(instance_id.to_string()))?;
        
        // æ·»åŠ åˆ°é˜Ÿåˆ—
        let envelope = SignalEnvelope {
            signal_name: signal_name.to_string(),
            data,
            timestamp: chrono::Utc::now(),
        };
        
        channel.queue.lock().unwrap().push_back(envelope);
        
        // å”¤é†’ç­‰å¾…çš„å·¥ä½œæµ
        channel.waker.notify_one();
        
        Ok(())
    }
    
    /// ç­‰å¾…Signal
    pub async fn await_signal(
        &self,
        instance_id: &str,
        signal_name: &str,
    ) -> Result<Value, SignalError> {
        let channels = self.channels.read().unwrap();
        let channel = channels.get(instance_id)
            .ok_or(SignalError::InstanceNotFound(instance_id.to_string()))?;
        
        let waker = channel.waker.clone();
        let queue = channel.queue.clone();
        
        drop(channels); // é‡Šæ”¾è¯»é”
        
        loop {
            // æ£€æŸ¥é˜Ÿåˆ—ä¸­æ˜¯å¦æœ‰åŒ¹é…çš„Signal
            {
                let mut q = queue.lock().unwrap();
                if let Some(pos) = q.iter().position(|e| e.signal_name == signal_name) {
                    let envelope = q.remove(pos).unwrap();
                    return Ok(envelope.data);
                }
            }
            
            // ç­‰å¾…æ–°Signal
            waker.notified().await;
        }
    }
}
```

**äº¤ä»˜ç‰©:**

- [ ] Signalæœºåˆ¶å®ç°
- [ ] SignalManagerå®ç°
- [ ] ä¸WorkflowEngineé›†æˆ
- [ ] æµ‹è¯•ç”¨ä¾‹

#### ä»»åŠ¡2.2: Queryæœºåˆ¶è®¾è®¡ä¸å®ç°

**ä¼˜å…ˆçº§**: ğŸ”´ P0  
**ä¼°ç®—å·¥æ—¶**: 4å¤©  

```rust
// src/query.rs

/// Queryå¤„ç†å™¨trait
#[async_trait]
pub trait QueryHandler: Send + Sync {
    /// Queryç»“æœç±»å‹
    type Result: Serialize + Send;
    
    /// å¤„ç†Query
    async fn handle(&self) -> Result<Self::Result, QueryError>;
}

/// Queryç®¡ç†å™¨
pub struct QueryManager {
    /// Queryå¤„ç†å™¨
    handlers: Arc<RwLock<HashMap<String, HashMap<String, Box<dyn DynQueryHandler>>>>>,
}

impl QueryManager {
    pub fn new() -> Self {
        Self {
            handlers: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    /// æ³¨å†ŒQueryå¤„ç†å™¨
    pub fn register_handler<H>(
        &self,
        instance_id: &str,
        query_name: &str,
        handler: H,
    ) where
        H: QueryHandler + 'static,
    {
        let mut handlers = self.handlers.write().unwrap();
        handlers.entry(instance_id.to_string())
            .or_insert_with(HashMap::new)
            .insert(
                query_name.to_string(),
                Box::new(QueryHandlerAdapter::new(handler))
            );
    }
    
    /// æ‰§è¡ŒQuery
    pub async fn execute_query(
        &self,
        instance_id: &str,
        query_name: &str,
    ) -> Result<Value, QueryError> {
        let handlers = self.handlers.read().unwrap();
        let instance_handlers = handlers.get(instance_id)
            .ok_or(QueryError::InstanceNotFound(instance_id.to_string()))?;
        
        let handler = instance_handlers.get(query_name)
            .ok_or(QueryError::QueryNotFound(query_name.to_string()))?;
        
        // æ‰§è¡ŒQueryï¼ˆä¸åº”è¯¥ä¿®æ”¹çŠ¶æ€ï¼‰
        handler.handle_dyn().await
    }
}
```

**äº¤ä»˜ç‰©:**

- [ ] Queryæœºåˆ¶å®ç°
- [ ] QueryManagerå®ç°
- [ ] ä¸WorkflowEngineé›†æˆ
- [ ] æµ‹è¯•ç”¨ä¾‹

### Week 9-12: æŒä¹…åŒ–å¢å¼º ğŸ”´

#### ä»»åŠ¡3.1: äº‹ä»¶æº¯æºæ¶æ„

**ä¼˜å…ˆçº§**: ğŸ”´ P0  
**ä¼°ç®—å·¥æ—¶**: 7å¤©  

```rust
// src/persistence/event_sourcing.rs

/// å·¥ä½œæµäº‹ä»¶
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum WorkflowEvent {
    /// å·¥ä½œæµå¯åŠ¨
    WorkflowStarted {
        workflow_id: String,
        workflow_name: String,
        input: Value,
        timestamp: i64,
    },
    /// Activityå¯åŠ¨
    ActivityStarted {
        workflow_id: String,
        activity_name: String,
        input: Value,
        timestamp: i64,
    },
    /// Activityå®Œæˆ
    ActivityCompleted {
        workflow_id: String,
        activity_name: String,
        output: Value,
        timestamp: i64,
    },
    /// Activityå¤±è´¥
    ActivityFailed {
        workflow_id: String,
        activity_name: String,
        error: String,
        timestamp: i64,
    },
    /// Signalæ¥æ”¶
    SignalReceived {
        workflow_id: String,
        signal_name: String,
        data: Value,
        timestamp: i64,
    },
    /// çŠ¶æ€è½¬æ¢
    StateTransitioned {
        workflow_id: String,
        from_state: String,
        to_state: String,
        timestamp: i64,
    },
    /// å·¥ä½œæµå®Œæˆ
    WorkflowCompleted {
        workflow_id: String,
        output: Value,
        timestamp: i64,
    },
    /// å·¥ä½œæµå¤±è´¥
    WorkflowFailed {
        workflow_id: String,
        error: String,
        timestamp: i64,
    },
}

/// äº‹ä»¶å­˜å‚¨
#[async_trait]
pub trait EventStore: Send + Sync {
    /// è¿½åŠ äº‹ä»¶
    async fn append_event(&self, event: WorkflowEvent) -> Result<u64, EventStoreError>;
    
    /// è·å–äº‹ä»¶æµ
    async fn get_events(
        &self,
        workflow_id: &str,
        from_sequence: u64,
    ) -> Result<Vec<WorkflowEvent>, EventStoreError>;
    
    /// è·å–æœ€æ–°åºåˆ—å·
    async fn get_latest_sequence(&self, workflow_id: &str) -> Result<u64, EventStoreError>;
}

/// å†…å­˜äº‹ä»¶å­˜å‚¨å®ç°
pub struct InMemoryEventStore {
    events: Arc<RwLock<HashMap<String, Vec<(u64, WorkflowEvent)>>>>,
    sequences: Arc<RwLock<HashMap<String, u64>>>,
}

impl InMemoryEventStore {
    pub fn new() -> Self {
        Self {
            events: Arc::new(RwLock::new(HashMap::new())),
            sequences: Arc::new(RwLock::new(HashMap::new())),
        }
    }
}

#[async_trait]
impl EventStore for InMemoryEventStore {
    async fn append_event(&self, event: WorkflowEvent) -> Result<u64, EventStoreError> {
        let workflow_id = event.workflow_id().to_string();
        
        let mut events = self.events.write().unwrap();
        let mut sequences = self.sequences.write().unwrap();
        
        // è·å–ä¸‹ä¸€ä¸ªåºåˆ—å·
        let sequence = sequences.entry(workflow_id.clone())
            .and_modify(|s| *s += 1)
            .or_insert(1);
        
        // è¿½åŠ äº‹ä»¶
        events.entry(workflow_id.clone())
            .or_insert_with(Vec::new)
            .push((*sequence, event));
        
        Ok(*sequence)
    }
    
    async fn get_events(
        &self,
        workflow_id: &str,
        from_sequence: u64,
    ) -> Result<Vec<WorkflowEvent>, EventStoreError> {
        let events = self.events.read().unwrap();
        
        if let Some(workflow_events) = events.get(workflow_id) {
            let filtered = workflow_events.iter()
                .filter(|(seq, _)| *seq >= from_sequence)
                .map(|(_, event)| event.clone())
                .collect();
            
            Ok(filtered)
        } else {
            Ok(Vec::new())
        }
    }
    
    async fn get_latest_sequence(&self, workflow_id: &str) -> Result<u64, EventStoreError> {
        let sequences = self.sequences.read().unwrap();
        Ok(*sequences.get(workflow_id).unwrap_or(&0))
    }
}

/// çŠ¶æ€é‡å»ºå™¨
pub struct StateRebuilder {
    event_store: Arc<dyn EventStore>,
}

impl StateRebuilder {
    pub fn new(event_store: Arc<dyn EventStore>) -> Self {
        Self { event_store }
    }
    
    /// ä»äº‹ä»¶é‡å»ºå·¥ä½œæµçŠ¶æ€
    pub async fn rebuild_state(
        &self,
        workflow_id: &str,
    ) -> Result<WorkflowInstance, StateRebuildError> {
        // è·å–æ‰€æœ‰äº‹ä»¶
        let events = self.event_store.get_events(workflow_id, 0).await?;
        
        // ä»äº‹ä»¶é‡å»ºçŠ¶æ€
        let mut state_builder = WorkflowStateBuilder::new(workflow_id);
        
        for event in events {
            state_builder.apply_event(event)?;
        }
        
        state_builder.build()
    }
}
```

**äº¤ä»˜ç‰©:**

- [ ] äº‹ä»¶æº¯æºæ¶æ„å®ç°
- [ ] EventStore traitå’Œå®ç°
- [ ] çŠ¶æ€é‡å»ºæœºåˆ¶
- [ ] WALæ”¯æŒ
- [ ] æ€§èƒ½æµ‹è¯•

---

## ç¬¬äºŒé˜¶æ®µ: ä¼ä¸šç‰¹æ€§å¢å¼º (Week 13-24)

### Week 13-16: ç‰ˆæœ¬ç®¡ç† ğŸŸ¡

#### ä»»åŠ¡4.1: å·¥ä½œæµç‰ˆæœ¬ç³»ç»Ÿ

**ä¼°ç®—å·¥æ—¶**: 8å¤©

```rust
// src/versioning/mod.rs

use semver::{Version, VersionReq};

pub struct WorkflowVersion {
    pub definition: WorkflowDefinition,
    pub version: Version,
    pub compatible_with: Vec<VersionReq>,
    pub deprecated: bool,
    pub migration_rules: Vec<MigrationRule>,
}

pub struct MigrationRule {
    pub from_version: VersionReq,
    pub to_version: Version,
    pub migration_fn: Box<dyn Fn(WorkflowInstance) -> Result<WorkflowInstance, MigrationError>>,
}

pub struct VersionManager {
    versions: Arc<RwLock<HashMap<String, BTreeMap<Version, WorkflowVersion>>>>,
}

impl VersionManager {
    pub fn register_version(&self, workflow_name: String, version: WorkflowVersion) {
        // æ³¨å†Œç‰ˆæœ¬
    }
    
    pub fn get_compatible_version(
        &self,
        workflow_name: &str,
        required_version: &VersionReq,
    ) -> Option<&WorkflowVersion> {
        // æŸ¥æ‰¾å…¼å®¹ç‰ˆæœ¬
    }
    
    pub async fn migrate_instance(
        &self,
        instance: WorkflowInstance,
        target_version: &Version,
    ) -> Result<WorkflowInstance, MigrationError> {
        // è¿ç§»å®ä¾‹åˆ°æ–°ç‰ˆæœ¬
    }
}
```

### Week 17-20: å­å·¥ä½œæµæ”¯æŒ ğŸŸ¡

#### ä»»åŠ¡5.1: å­å·¥ä½œæµæœºåˆ¶

**ä¼°ç®—å·¥æ—¶**: 6å¤©

```rust
// src/child_workflow.rs

pub struct ChildWorkflowBuilder<'a> {
    parent_id: String,
    engine: &'a WorkflowEngine,
    workflow_name: String,
    input: Option<Value>,
    options: ChildWorkflowOptions,
}

pub struct ChildWorkflowOptions {
    pub inherit_parent_timeout: bool,
    pub propagate_failures: bool,
    pub wait_for_cancellation: bool,
}

impl WorkflowEngine {
    pub fn child_workflow<'a>(
        &'a self,
        parent_id: &str,
        workflow_name: &str,
    ) -> ChildWorkflowBuilder<'a> {
        ChildWorkflowBuilder {
            parent_id: parent_id.to_string(),
            engine: self,
            workflow_name: workflow_name.to_string(),
            input: None,
            options: ChildWorkflowOptions::default(),
        }
    }
}

impl<'a> ChildWorkflowBuilder<'a> {
    pub fn input(mut self, input: Value) -> Self {
        self.input = Some(input);
        self
    }
    
    pub async fn execute(self) -> Result<ChildWorkflowHandle, WorkflowError> {
        // å¯åŠ¨å­å·¥ä½œæµ
    }
}
```

### Week 21-24: å¯è§‚æµ‹æ€§å¢å¼º ğŸŸ¡

#### ä»»åŠ¡6.1: åˆ†å¸ƒå¼è¿½è¸ªé›†æˆ

**ä¼°ç®—å·¥æ—¶**: 5å¤©

```rust
// src/observability/tracing.rs

use opentelemetry::trace::{Tracer, Span};

pub struct WorkflowTracer {
    tracer: Box<dyn Tracer>,
}

impl WorkflowEngine {
    pub fn trace_workflow_execution(
        &self,
        instance_id: &str,
    ) -> WorkflowSpan {
        let span = self.tracer.start(format!("workflow.{}", instance_id));
        WorkflowSpan { span }
    }
}
```

---

## ç¬¬ä¸‰é˜¶æ®µ: ç”Ÿäº§å°±ç»ª (Week 25-48)

### Week 25-32: åˆ†å¸ƒå¼éƒ¨ç½² ğŸŸ¢

#### ä»»åŠ¡7.1: é›†ç¾¤æ”¯æŒ

**ä¼°ç®—å·¥æ—¶**: 15å¤©

### Week 33-40: Temporaläº’æ“ä½œ ğŸŸ¢

#### ä»»åŠ¡8.1: Temporalå…¼å®¹å±‚

**ä¼°ç®—å·¥æ—¶**: 12å¤©

### Week 41-48: æ€§èƒ½ä¼˜åŒ–ä¸ç¨³å®šæ€§ ğŸŸ¢

#### ä»»åŠ¡9.1: ç”Ÿäº§ç¯å¢ƒéªŒè¯

**ä¼°ç®—å·¥æ—¶**: 20å¤©

---

## ğŸ“Š è¿›åº¦è·Ÿè¸ª

### å…³é”®é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | ç›®æ ‡æ—¥æœŸ | çŠ¶æ€ | å®Œæˆåº¦ |
|--------|---------|------|--------|
| M1: ActivityæŠ½è±¡å®Œæˆ | Week 4 | ğŸ“‹ å¾…å¼€å§‹ | 0% |
| M2: Signal/Queryå®Œæˆ | Week 8 | ğŸ“‹ å¾…å¼€å§‹ | 0% |
| M3: äº‹ä»¶æº¯æºå®Œæˆ | Week 12 | ğŸ“‹ å¾…å¼€å§‹ | 0% |
| M4: v2.0 Betaå‘å¸ƒ | Week 12 | ğŸ“‹ å¾…å¼€å§‹ | 0% |
| M5: ç‰ˆæœ¬ç®¡ç†å®Œæˆ | Week 16 | ğŸ“‹ å¾…å¼€å§‹ | 0% |
| M6: å­å·¥ä½œæµå®Œæˆ | Week 20 | ğŸ“‹ å¾…å¼€å§‹ | 0% |
| M7: v2.0 RCå‘å¸ƒ | Week 24 | ğŸ“‹ å¾…å¼€å§‹ | 0% |
| M8: åˆ†å¸ƒå¼éƒ¨ç½²å®Œæˆ | Week 32 | ğŸ“‹ å¾…å¼€å§‹ | 0% |
| M9: Temporaläº’æ“ä½œå®Œæˆ | Week 40 | ğŸ“‹ å¾…å¼€å§‹ | 0% |
| M10: v2.0æ­£å¼å‘å¸ƒ | Week 48 | ğŸ“‹ å¾…å¼€å§‹ | 0% |

### é£é™©ä¸ç¼“è§£æªæ–½

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|-----|------|------|---------|
| è®¾è®¡å¤æ‚åº¦è¶…é¢„æœŸ | ğŸ”´ é«˜ | ğŸŸ¡ ä¸­ | åˆ†é˜¶æ®µå®æ–½ï¼ŒMVPä¼˜å…ˆ |
| æ€§èƒ½å›å½’ | ğŸ”´ é«˜ | ğŸŸ¢ ä½ | æŒç»­æ€§èƒ½æµ‹è¯•ï¼ŒåŸºå‡†ç›‘æ§ |
| å‘åå…¼å®¹æ€§é—®é¢˜ | ğŸŸ¡ ä¸­ | ğŸŸ¡ ä¸­ | ç‰ˆæœ¬éš”ç¦»ï¼Œè¿ç§»å·¥å…· |
| èµ„æºä¸è¶³ | ğŸŸ¡ ä¸­ | ğŸŸ¢ ä½ | ç¤¾åŒºè´¡çŒ®ï¼Œä¼˜å…ˆçº§è°ƒæ•´ |

---

## ğŸ“š å‚è€ƒèµ„æº

### å¼€å‘æŒ‡å—

- [Activityå¼€å‘æŒ‡å—](./guides/activity_development.md)
- [Signal/Queryä½¿ç”¨æŒ‡å—](./guides/signal_query_guide.md)
- [æŒä¹…åŒ–é…ç½®æŒ‡å—](./guides/persistence_config.md)

### ç¤ºä¾‹ä»£ç 

- [Activityç¤ºä¾‹](../examples/activity_examples/)
- [Signal/Queryç¤ºä¾‹](../examples/signal_query_examples/)
- [äº‹ä»¶æº¯æºç¤ºä¾‹](../examples/event_sourcing_examples/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2025-10-26  
**ç»´æŠ¤è€…**: workflow_rustæ ¸å¿ƒå›¢é˜Ÿ
